{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Amazon_Reviews_Sentiment_Analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PharahMain/Thinkful/blob/master/Amazon_Reviews_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3CxSmWG34j5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.osuosl.org/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0KJwTP64BK0",
        "colab_type": "code",
        "outputId": "eda0e839-48b6-4002-d4ff-94a375aec735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "# Install spark-related depdencies for Python\n",
        "!pip install -q findspark\n",
        "!pip install pyspark"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 124kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7 (from pyspark)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 43.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130387 sha256=96143b7ca1c63aa3d1f83312b5f7458d841522dde58d578876871ae26c0867c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq6UTq2K4W1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up required environment variables\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8vr0sIu4l94",
        "colab_type": "code",
        "outputId": "06d4d2dc-6b35-4722-b143-cc5765f1eb14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "# Point Colaboratory to Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW_hof-N4pLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "from pyspark.sql.functions import isnan, when, count, col"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sVADULS49-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "JSON_PATH = \"/content/gdrive/My Drive/Colab Datasets/amazon_reviews_video_games.json\" \n",
        "APP_NAME = \"Amazon Reviews Sentiment Analysis\"\n",
        "SPARK_URL = \"local[*]\"\n",
        "RANDOM_SEED = 141107\n",
        "TRAINING_DATA_RATIO = 0.8\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpMR_WleW5dq",
        "colab_type": "text"
      },
      "source": [
        "First let's build a spark instance we will be working from."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDxEYTgVW1_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spark = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDhpqperUbUg",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look closer look at the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAjGIEp-UhA4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "412311e5-1139-42fe-a4dd-93f4ecae12ab"
      },
      "source": [
        "df = spark.read.json(JSON_PATH)\n",
        "df.show(5)\n",
        "print(f\"There are {df.count()} reviews in this dataset\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
            "|      asin|helpful|overall|          reviewText| reviewTime|    reviewerID|        reviewerName|             summary|unixReviewTime|\n",
            "+----------+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
            "|0700099867|[8, 12]|    1.0|Installing the ga...| 07 9, 2012|A2HD75EMZR8QLN|                 123|Pay to unlock con...|    1341792000|\n",
            "|0700099867| [0, 0]|    4.0|If you like rally...|06 30, 2013|A3UR8NLLY1ZHCX|Alejandro Henao \"...|     Good rally game|    1372550400|\n",
            "|0700099867| [0, 0]|    1.0|1st shipment rece...|06 28, 2014|A1INA0F5CWW3J4|Amazon Shopper \"M...|           Wrong key|    1403913600|\n",
            "|0700099867|[7, 10]|    3.0|I got this versio...|09 14, 2011|A1DLMTOTHQ4AST|            ampgreen|awesome game, if ...|    1315958400|\n",
            "|0700099867| [2, 2]|    4.0|I had Dirt 2 on X...|06 14, 2011|A361M14PU2GUEG|Angry Ryan \"Ryan ...|              DIRT 3|    1308009600|\n",
            "+----------+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "There are 231780 reviews in this dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lp1L1Rq9XtWu",
        "colab_type": "text"
      },
      "source": [
        "Let's drop columns we don't need for this analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j9zQHbTWt1E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "d7c60d7f-5c8c-4cf1-befe-84fb84cf83ba"
      },
      "source": [
        "# drop all columns except 'overall' and 'reviewText'. Or, inversely, we can just select the two columns of interest.\n",
        "df = df.select('overall', 'reviewText')\n",
        "df.show(5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------------+\n",
            "|overall|          reviewText|\n",
            "+-------+--------------------+\n",
            "|    1.0|Installing the ga...|\n",
            "|    4.0|If you like rally...|\n",
            "|    1.0|1st shipment rece...|\n",
            "|    3.0|I got this versio...|\n",
            "|    4.0|I had Dirt 2 on X...|\n",
            "+-------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQsglYmcwrCs",
        "colab_type": "text"
      },
      "source": [
        "Since spark only accepts numerical values in its machine learning algorithms, we need to make some adjustments. Let's somewhat arbitrarily draw a line between favorable and unfavorable sentiment by selecting scores above 3.0 to be 'favorable' or 1 in this case, and 3.0 and lower scores as 'unfavorable' or 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8-gzcfcYHGu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "3575d3a6-88c3-4c15-fc73-7210319c1540"
      },
      "source": [
        "df = df.withColumn('overall', when(col('overall') > 3.0, 1).otherwise(0))\n",
        "df.show(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------------+\n",
            "|overall|          reviewText|\n",
            "+-------+--------------------+\n",
            "|      0|Installing the ga...|\n",
            "|      1|If you like rally...|\n",
            "|      0|1st shipment rece...|\n",
            "|      0|I got this versio...|\n",
            "|      1|I had Dirt 2 on X...|\n",
            "+-------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly0462IsO6JZ",
        "colab_type": "text"
      },
      "source": [
        "*Alternatively, I can use StringIndexer to retain all 5 (1-5) ratings. But for now, I will keep it simple.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgXoKnE5zJUi",
        "colab_type": "text"
      },
      "source": [
        "Now we need to introduce a dictionary with favorable and unfavorable words to compare with each reviewText."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VStx2ZjfzBK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "favor_words = ['love', 'great', 'good', 'recommend', 'fun', 'amazing']\n",
        "unfavor_words = ['disappointing', 'suck', 'bad', 'waste', 'return', 'not recommend']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q692D53b18ZR",
        "colab_type": "text"
      },
      "source": [
        "We will then compare the words in both lists with each reviewText and create a feature set for each entry."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufUYYSMC3ocV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "251bfa8c-8597-4f0a-d44a-fd8b0aaa443e"
      },
      "source": [
        "#df.withColumn('love', when(col('reviewText').like('%love%'), 1).otherwise(0)).show()\n",
        "df.show(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------------+\n",
            "|overall|          reviewText|\n",
            "+-------+--------------------+\n",
            "|      0|Installing the ga...|\n",
            "|      1|If you like rally...|\n",
            "|      0|1st shipment rece...|\n",
            "|      0|I got this versio...|\n",
            "|      1|I had Dirt 2 on X...|\n",
            "+-------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T_UNYtn0FHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_selector(dataframe, word_list):\n",
        "  \n",
        "    for word in word_list:\n",
        "        \n",
        "        dataframe = dataframe.withColumn(word, when(col('reviewText').like(f\"%{word}%\"), True).otherwise(False))\n",
        "                \n",
        "    return dataframe\n",
        "    \n",
        "df = feature_selector(df, favor_words)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQJ8yHqI2qpq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "9fa9d9ec-9903-4391-f0fb-f199648df22b"
      },
      "source": [
        "# repeat with unfavorable words\n",
        "df = feature_selector(df, unfavor_words)\n",
        "df.show(5)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------------+-----+-----+-----+---------+-----+-------+-------------+-----+-----+-----+------+-------------+\n",
            "|overall|          reviewText| love|great| good|recommend|  fun|amazing|disappointing| suck|  bad|waste|return|not recommend|\n",
            "+-------+--------------------+-----+-----+-----+---------+-----+-------+-------------+-----+-----+-----+------+-------------+\n",
            "|      0|Installing the ga...|false|false|false|    false|false|  false|        false|false|false|false| false|        false|\n",
            "|      1|If you like rally...|false|false|false|    false| true|  false|        false|false|false|false| false|        false|\n",
            "|      0|1st shipment rece...|false|false| true|    false|false|  false|        false|false|false|false| false|        false|\n",
            "|      0|I got this versio...|false| true| true|    false| true|  false|        false|false|false| true|  true|        false|\n",
            "|      1|I had Dirt 2 on X...|false|false|false|    false| true|  false|        false|false|false|false| false|        false|\n",
            "+-------+--------------------+-----+-----+-----+---------+-----+-------+-------------+-----+-----+-----+------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8kwRmKCD0kr",
        "colab_type": "text"
      },
      "source": [
        "Next we need to vectorize the features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4P1Kob-_gdj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "de934c70-5899-488b-c7e4-a027913868fb"
      },
      "source": [
        "# let's separate out the feature columns\n",
        "features = df.drop('overall', 'reviewText')\n",
        "features.show(5)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-----+-----+---------+-----+-------+-------------+-----+-----+-----+------+-------------+\n",
            "| love|great| good|recommend|  fun|amazing|disappointing| suck|  bad|waste|return|not recommend|\n",
            "+-----+-----+-----+---------+-----+-------+-------------+-----+-----+-----+------+-------------+\n",
            "|false|false|false|    false|false|  false|        false|false|false|false| false|        false|\n",
            "|false|false|false|    false| true|  false|        false|false|false|false| false|        false|\n",
            "|false|false| true|    false|false|  false|        false|false|false|false| false|        false|\n",
            "|false| true| true|    false| true|  false|        false|false|false| true|  true|        false|\n",
            "|false|false|false|    false| true|  false|        false|false|false|false| false|        false|\n",
            "+-----+-----+-----+---------+-----+-------+-------------+-----+-----+-----+------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvTyFa_vAco7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# time to build vectors for each review\n",
        "assembler = VectorAssembler(inputCols=features.columns, outputCol=\"features_vector\")\n",
        "#assembler.transform(feature_cols).show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B02qKHMXbkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data into training and validation sets (30% held out for testing)\n",
        "(trainingData, testData) = df.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
        "\n",
        "# Train a Naive-Bayes model.\n",
        "nb = NaiveBayes(featuresCol=\"features_vector\", labelCol=\"overall\", modelType=\"bernoulli\")\n",
        "\n",
        "# Chain indexers and forest in a Pipeline\n",
        "pipeline = Pipeline(stages=[assembler, nb])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxPJDIdCZFwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build model using the training data\n",
        "model = pipeline.fit(trainingData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVTd46cwcox7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make predictions with the test data\n",
        "predictions = model.transform(testData)\n",
        "#predictions.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ6Jf87md5xd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ae305551-a34c-419d-eac0-769a59391880"
      },
      "source": [
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = BinaryClassificationEvaluator(\n",
        "    labelCol=\"overall\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
        "print(f\"Accuracy = {accuracy:g}\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Error = 0.477458\n",
            "Accuracy = 0.522542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQpeaEctfoOa",
        "colab_type": "text"
      },
      "source": [
        "That is awful. But this is to be expected since we are using a very simple dictionary consisting of 12 words to try to predict a sentiment. I will want to expand this analysis by deploying additional tools like word2vec."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8BGFSS4fEXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}