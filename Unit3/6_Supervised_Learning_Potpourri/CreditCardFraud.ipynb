{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Credit Card Fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are working with preprocessed data, most of the features we are working with is obsecured. Good news is that we won't have to do much, if at all, data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's load the necessary packages and the data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "df = pd.read_csv('../../../Data/creditcard.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# I want to see if there is a significant difference in dollar amounts of legitimate vs fraudulent transactions\n",
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.set(style='white')\n",
    "\n",
    "sns.boxplot(x='Class', y='Amount', data=df)\n",
    "plt.title('$ Amount: Legitimate Vs Fradulent')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dollar amounts for the legitimate tranasctions dwarf those of the fraudulent kind, so it looks like the amount alone isn't a very good indicator of fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since principal component analysis was already done, we can trust that the features have already been reduced to describe the data. So let's move on to see if we can build a model using the data. In the documents for the data, it was mentioned that there is a very small number of fraudulent transactions so let's take a look for ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to see how we can split the data, I want to see how many records we are working with\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213605 71202 213605 71202\n"
     ]
    }
   ],
   "source": [
    "# 280k+ rows, so since the percentage of fraudulent transactions is very low, let's leave a sizeable test data.\n",
    "X = df.drop(['Class'], axis=1)\n",
    "y = df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=26)\n",
    "print(X_train.shape[0], X_test.shape[0], y_train.shape[0], y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the vanilla logistic regression model to see how it does compared to ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1.73 seconds\n",
      "Coefficients:\n",
      " [[-8.61984950e-05  4.58742559e-01 -8.13468164e-01 -7.93024314e-01\n",
      "   2.40784726e-01  2.43191145e-01 -1.16982149e-01  4.12788544e-01\n",
      "  -4.81611769e-01 -5.68307592e-01 -3.41137398e-01 -2.05237717e-01\n",
      "  -4.46035763e-02 -4.50787376e-01 -1.08045390e+00 -4.14782817e-01\n",
      "  -4.38092433e-01 -7.59195754e-01 -3.10311534e-02  6.97094742e-02\n",
      "   6.17229661e-02  3.13219839e-01  3.62128912e-01  6.67046822e-02\n",
      "  -2.30494582e-02 -3.85875302e-01  6.34267856e-02 -6.36541182e-02\n",
      "   8.21358361e-02 -7.63027010e-03]]\n",
      "R2 Score:  0.9990028369989608\n",
      "Confusion Matrix:\n",
      " [[71033    37]\n",
      " [   34    98]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# start the clock\n",
    "start_time = time.time()\n",
    "\n",
    "lr = linear_model.LogisticRegression(solver='lbfgs', penalty='none')\n",
    "lr_model = lr.fit(X_train, y_train)\n",
    "y_pred = lr_model.predict(X_test)\n",
    "c_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# measure elapsed time\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print('Elapsed time: %0.2f seconds' % elapsed)\n",
    "print('Coefficients:\\n', lr_model.coef_)\n",
    "print('R2 Score: ', lr_model.score(X_test, y_test))\n",
    "print('Confusion Matrix:\\n', c_mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 71202 records, only 135 were flagged as fraudulent. Since the nature of the dataset has a skewed distribution, it is hard to celebrate our model's accuracy of 99.9%. It is also worrying that we flagged 37 legitimate transactions as fraudulent, while missing 34 fraudulent transactions. Put in context of total transactions, sensitivity(Type I or false positive) was 34/71084 or 0.05% and specificity(Type II or false negative) was 34/132 or 25.76%. In this case, we are more interested in falsely classified fraudulent transactions, since this means that we missed 25% of all fradulent transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1.67 seconds\n",
      "Coefficients:\n",
      " [[-8.64852045e-05  4.99619948e-01 -8.55491289e-01 -8.05837795e-01\n",
      "   2.32431174e-01  2.60382686e-01 -1.07872138e-01  4.35495163e-01\n",
      "  -5.02360832e-01 -5.93688850e-01 -3.49378198e-01 -2.20131275e-01\n",
      "  -1.83907968e-02 -4.63251504e-01 -1.11528994e+00 -4.28354454e-01\n",
      "  -4.39727281e-01 -7.64006423e-01 -2.48020005e-02  6.64415129e-02\n",
      "   6.02390438e-02  3.18291307e-01  3.77082281e-01  6.71750410e-02\n",
      "  -2.77397511e-02 -3.89578391e-01  6.35397539e-02 -7.63894015e-02\n",
      "   8.52842604e-02 -8.30248182e-03]]\n",
      "R2 Score:  0.9989642217618764\n",
      "Confusion Matrix:\n",
      " [[56825    28]\n",
      " [   31    78]]\n",
      "Type II Error:  0.28440366972477066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Let's see if increasing the size of the training data will help\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=26)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "lr2 = linear_model.LogisticRegression(solver='lbfgs', penalty='none')\n",
    "lr_model2 = lr2.fit(X_train, y_train)\n",
    "y_pred = lr_model2.predict(X_test)\n",
    "c_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print('Elapsed time: %0.2f seconds' % elapsed)\n",
    "print('Coefficients:\\n', lr_model2.coef_)\n",
    "print('R2 Score: ', lr_model2.score(X_test, y_test))\n",
    "print('Confusion Matrix:\\n', c_mat)\n",
    "print('Type II Error: ', c_mat[1][0]/sum(c_mat[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our type II error got worse to 28.44%. Let's go back to leaving out 25% of data for testing and try gradient boosting model to compare its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213605 71202 213605 71202\n",
      "0    71070\n",
      "1      132\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=26)\n",
    "print(X_train.shape[0], X_test.shape[0], y_train.shape[0], y_test.shape[0])\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 70.34 seconds\n",
      "Accuracy:  0.9992556388865481\n",
      "Confusion Matrix:\n",
      " [[71042    28]\n",
      " [   25   107]]\n",
      "Type II Error:  0.1893939393939394\n"
     ]
    }
   ],
   "source": [
    "# gradient boost model\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "clf = ensemble.GradientBoostingClassifier(n_estimators=900, max_depth=11)\n",
    "clf_model = clf.fit(X_train, y_train)\n",
    "clf_y_pred = clf_model.predict(X_test)\n",
    "clf_c_mat = confusion_matrix(y_test, clf_y_pred)\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print('Elapsed time: %0.2f seconds' % elapsed)\n",
    "print('Accuracy: ', clf_model.score(X_test, y_test))\n",
    "print('Confusion Matrix:\\n', clf_c_mat)\n",
    "print('Type II Error: ', clf_c_mat[1][0]/sum(clf_c_mat[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our gradient boosting model gave us 28.79% specificity. Marked improvement as it should be for an ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 734.08 seconds\n",
      "Accuracy:  0.9996348417179293\n",
      "Confusion Matrix:\n",
      " [[71067     3]\n",
      " [   23   109]]\n",
      "Type II Error:  0.17424242424242425\n"
     ]
    }
   ],
   "source": [
    "# Random forest model\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier(n_estimators=900, max_depth=11)\n",
    "rfc_model = rfc.fit(X_train, y_train)\n",
    "rfc_y_pred = rfc_model.predict(X_test)\n",
    "rfc_c_mat = confusion_matrix(y_test, rfc_y_pred)\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print('Elapsed time: %0.2f seconds' % elapsed)\n",
    "print('Accuracy: ', rfc_model.score(X_test, y_test))\n",
    "print('Confusion Matrix:\\n', rfc_c_mat)\n",
    "print('Type II Error: ', rfc_c_mat[1][0]/sum(rfc_c_mat[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest classifier gets us 22.01% and mis-classified 24 out of 109 fraudulent transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 222.61 seconds\n",
      "Accuracy:  0.9984691441251651\n",
      "Confusion Matrix:\n",
      " [[71049    21]\n",
      " [   88    44]]\n",
      "Type II Error:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# SVM classifier\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "svc = svm.SVC(kernel='linear')\n",
    "svc_model = svc.fit(X_train, y_train)\n",
    "svc_y_pred = svc_model.predict(X_test)\n",
    "svc_c_mat = confusion_matrix(y_test, svc_y_pred)\n",
    "\n",
    "elpased = time.time() - start_time\n",
    "\n",
    "print('Elapsed time: %0.2f seconds' % elapsed)\n",
    "print('Accuracy: ', svc_model.score(X_test, y_test))\n",
    "print('Confusion Matrix:\\n', svc_c_mat)\n",
    "print('Type II Error: ', svc_c_mat[1][0]/sum(svc_c_mat[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 3.55 seconds\n",
      "Accuracy:  0.9982865649841297\n",
      "Confusion Matrix:\n",
      " [[71069     1]\n",
      " [  121    11]]\n",
      "Type II Error:  0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "# KNN Classifier\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model = knn.fit(X_train, y_train)\n",
    "knn_y_pred = knn_model.predict(X_test)\n",
    "knn_c_mat = confusion_matrix(y_test, knn_y_pred)\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print('Elapsed time: %0.2f seconds' % elapsed)\n",
    "print('Accuracy: ', knn_model.score(X_test, y_test))\n",
    "print('Confusion Matrix:\\n', knn_c_mat)\n",
    "print('Type II Error: ', knn_c_mat[1][0]/sum(knn_c_mat[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasped time: 0.23 seconds\n",
      "Accuracy:  0.9992135052386169\n",
      "Confusion Matrix:\n",
      " [[71055    15]\n",
      " [   41    91]]\n",
      "Type II Error:  0.3106060606060606\n"
     ]
    }
   ],
   "source": [
    "# Naive-Bayes classifier\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "bn = BernoulliNB()\n",
    "bn_model = bn.fit(X_train, y_train)\n",
    "bn_y_pred = bn_model.predict(X_test)\n",
    "bn_c_mat = confusion_matrix(y_test, bn_y_pred)\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print('Elasped time: %0.2f seconds' % elapsed)\n",
    "print('Accuracy: ', bn_model.score(X_test, y_test))\n",
    "print('Confusion Matrix:\\n', bn_c_mat)\n",
    "print('Type II Error: ', bn_c_mat[1][0]/sum(bn_c_mat[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
